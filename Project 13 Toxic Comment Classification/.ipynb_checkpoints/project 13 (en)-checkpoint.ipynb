{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>An online store is launching a new service where customers are allowed to edit descriptions and comment other people's changes. My task is to develop a machine learning model with F1 score higher than 0.75 that will classify the positive and negative comments and look out for the latter ones, which also known as toxic, all in order to send them for moderation.</p>\n",
    "\n",
    "<p>Provided data are in a file called `toxic_comments.csv`. The column *text* has comments, and *toxic* is the target variable.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we know that the comments are written in English and there are almost 160 thousand comments in the provided dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    clean_and_lower = re.sub(r'[^a-zA-Z ]', ' ', text.lower()) #lower case and cleaning \n",
    "    result = [lemmatizer.lemmatize(w, 'v') for w in w_tokenizer.tokenize(clean_and_lower)] #tokenize and lemmatize the clean and lower\n",
    "    return \" \".join(result) #getting rid of commas and other punctuation symbols\n",
    "\n",
    "data['text_lemmatized'] = data['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted the words in lowercase, by leaving just the letters, created tokens, separated by commas, tokens were lemmatized considering part of speech = 'v' (verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i come...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                          text_lemmatized  \n",
       "0       explanation why the edit make under my usernam...  \n",
       "1       d aww he match this background colour i m seem...  \n",
       "2       hey man i m really not try to edit war it s ju...  \n",
       "3       more i can t make any real suggestions on impr...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159566  and for the second time of ask when your view ...  \n",
       "159567  you should be ashamed of yourself that be a ho...  \n",
       "159568  spitzer umm theres no actual article for prost...  \n",
       "159569  and it look like it be actually you who put on...  \n",
       "159570  and i really don t think you understand i come...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ww\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords as nltk_stopwords \n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english')) #download the English dictionary of stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Received stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data['text_lemmatized'], data['toxic'], train_size=0.85, random_state=0)\n",
    "#85% train\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size=0.5, random_state=0)\n",
    "#7.5% validation 7.5% test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Divided the full dataframe in training, validation and test datasets: 85%, 7.5% and 7.5% correspondingly.</p>\n",
    "<p>The number of rows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135635,), (135635,), (11968,), (11968,), (11968,), (11968,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_train = count_tf_idf.fit_transform(x_train)\n",
    "tf_idf_valid = count_tf_idf.transform(x_valid)\n",
    "tf_idf_test = count_tf_idf.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting TF-IDF taken into account the received stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix size: (135635, 142204)\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix size:\", tf_idf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ww\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train_pred = classifier.predict(tf_idf_train)\n",
    "tf_idf_valid_pred = classifier.predict(tf_idf_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7627772420443587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_logreg = f1_score(y_valid, tf_idf_valid_pred)\n",
    "\n",
    "print(f1_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression was trained and demonstrated F1 score equal to 0.763 in validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "f_one_score = make_scorer(f1_score, average='macro', greater_is_better = True)\n",
    "\n",
    "#param_grid = {\n",
    "#    'max_depth': range(90,201,10),\n",
    "#    'random_state': [0]\n",
    "#}\n",
    "\n",
    "#model = DecisionTreeClassifier()\n",
    "\n",
    "#grid_search = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 1, cv = 3, scoring = f_one_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#grid_search.fit(tf_idf_train, y_train)\n",
    "#print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'max_depth': 160, 'random_state': 0} <br>\n",
    "CPU times: user 58min 55s, sys: 2.02 s, total: 58min 57s <br>\n",
    "Wall time: 59min 4s <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7300479720889665\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = 160, random_state = 0)\n",
    "\n",
    "model.fit(tf_idf_train, y_train)\n",
    "y_valid_pred = model.predict(tf_idf_valid)\n",
    "print(f1_score(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>0.7300479720889665<br>\n",
    "Wall time: 1min 19s</p>\n",
    "\n",
    "<p>Decision Tree Classifier's F1 score is equal to 0.73, its result is .03 lower than logistic regression's, and also much slower, in order to get better results with DecisionTreeClassifier, I probably need a lot more time for training.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridParams = {\n",
    "#    'boosting_type': ['gbdt'],\n",
    "#    'learning_rate': [0.5, 0.1],\n",
    "#    'max_depth': range(10,51,10),\n",
    "#    'n_estimators': range(10,51,10),\n",
    "#    'random_state': [12345],\n",
    "#    #max_bin = [5]    \n",
    "#}\n",
    "\n",
    "#lgbclass = lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb_grid = GridSearchCV(lgbclass, gridParams, verbose=1, cv=3, scoring = f_one_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#lgb_grid.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'boosting_type': 'gbdt', <br>\n",
    " 'learning_rate': 0.5, <br>\n",
    " 'max_depth': 20, <br>\n",
    " 'n_estimators': 50, <br>\n",
    " 'random_state': 12345} <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.75 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.5, max_depth=20,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=50, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=12345, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = lgb.LGBMClassifier(boosting_type = 'gbdt', learning_rate = 0.5, max_depth = 20, \n",
    "                          n_estimators = 50, random_state = 12345)\n",
    "\n",
    "model.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wall time: 9.75 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.7728482697426797\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = model.predict(tf_idf_valid)\n",
    "f1_lgbm = f1_score(y_valid, y_valid_pred)\n",
    "print(\"F1 =\", f1_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM's gradient boosting models has shown the best result, though it's not really much better, but I believe that one can get even better results if he or she goes through more hyperparameter tuning and increases the number of n_estimators, cause the model has chosen the largest number of n_estimators that it was given, but it will increase the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "x_train = vstack([tf_idf_train, tf_idf_valid])\n",
    "y_train = pd.concat([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union of training and validation TF-IDF datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.5, max_depth=20,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=50, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=12345, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(boosting_type = 'gbdt', learning_rate = 0.5, max_depth = 20, \n",
    "                          n_estimators = 50, random_state = 12345)\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7796917497733455\n",
      "Wall time: 67.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = model.predict(tf_idf_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training both train and validation sets together have led the model to F1 score almost equal to 0.78."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
