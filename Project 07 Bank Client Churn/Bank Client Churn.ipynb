{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Upcoming Bank Client Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A considerable number of clients started leaving the bank that provided the data and it's best to retain them because as it turns out it's more cost-efficient than running a new advertising campaign to grow the client base anew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = pd.read_csv(/Churn.csv\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 10000 rows and 14 columns. 3 columns are odd for the future model (RowNumber, CustomerId, Surname), one column (Tenur) has empty values which should be filled, there's no need to change the types of data in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rid of columns that are irrelevant for machine learning, they have appeared due to data extraction operations from the database, where data come from, and may be needed to identify the person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42     2.0       0.00              1   \n",
       "1             608     Spain  Female   41     1.0   83807.86              1   \n",
       "2             502    France  Female   42     8.0  159660.80              3   \n",
       "3             699    France  Female   39     1.0       0.00              2   \n",
       "4             850     Spain  Female   43     2.0  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39     5.0       0.00              2   \n",
       "9996          516    France    Male   35    10.0   57369.61              1   \n",
       "9997          709    France  Female   36     7.0       0.00              1   \n",
       "9998          772   Germany    Male   42     3.0   75075.31              2   \n",
       "9999          792    France  Female   28     NaN  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 columns and 10000 rows now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, drop_first=True) \n",
    "#categorical data transformation with One Hot Encoding, avoiding dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenure               909\n",
      "Gender_Male            0\n",
      "Geography_Spain        0\n",
      "Geography_Germany      0\n",
      "Exited                 0\n",
      "EstimatedSalary        0\n",
      "IsActiveMember         0\n",
      "HasCrCard              0\n",
      "NumOfProducts          0\n",
      "Balance                0\n",
      "Age                    0\n",
      "CreditScore            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(data).sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 909 NaN values in *Tenure*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0    446\n",
       "9.0     882\n",
       "8.0     933\n",
       "7.0     925\n",
       "6.0     881\n",
       "5.0     927\n",
       "4.0     885\n",
       "3.0     928\n",
       "2.0     950\n",
       "1.0     952\n",
       "0.0     382\n",
       "NaN     909\n",
       "Name: Tenure, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure'].value_counts(dropna=False).sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenure is a number of properties. So I would assume that the person has no property in case it's not mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tenure'] = data['Tenure'].fillna(0) #filling NA with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore          0\n",
      "Age                  0\n",
      "Tenure               0\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "Geography_Germany    0\n",
      "Geography_Spain      0\n",
      "Gender_Male          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(data).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no empty value cells in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['Exited']\n",
    "features = data.drop('Exited', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_valid, target_valid, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Defining the features. 'Exited' is a target variable.</p>\n",
    "<p>I split the number of rows in train, validation and test sets. 60%, 20%, and 20% of the whole dataset accordingly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Sizes\n",
      "Training Set:     (6000, 11) (6000,)\n",
      "Validation Set:   (2000, 11) (2000,)\n",
      "Test Set:         (2000, 11) (2000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Set Sizes\")\n",
    "print(\"Training Set:    \", features_train.shape, target_train.shape)\n",
    "print(\"Validation Set:  \", features_valid.shape, target_valid.shape)\n",
    "print(\"Test Set:        \", features_test.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Accuracy = 0.7870\n",
      "F1 Score = 0.4818\n",
      "ROC-AUC  = 0.6717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "accuracy = accuracy_score(target_valid, predicted_valid)\n",
    "F1 = f1_score(target_valid, predicted_valid)\n",
    "\n",
    "probabilities = model.predict_proba(features_valid)\n",
    "probabilities_one = probabilities[:, 1]\n",
    "ROCAUC = roc_auc_score(target_valid, probabilities_one)\n",
    "\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(\"Accuracy =\", '{:.4f}'.format(round(accuracy,4)))\n",
    "print(\"F1 Score =\", '{:.4f}'.format(round(F1,4)))\n",
    "print(\"ROC-AUC  =\", '{:.4f}'.format(round(ROCAUC,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced Logistic Regression:\n",
      "Accuracy = 0.7815\n",
      "F1 Score = 0.0839\n",
      "ROC-AUC  = 0.6728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "accuracy = accuracy_score(target_valid, predicted_valid)\n",
    "F1 = f1_score(target_valid, predicted_valid)\n",
    "\n",
    "probabilities = model.predict_proba(features_valid)\n",
    "probabilities_one = probabilities[:, 1]\n",
    "ROCAUC = roc_auc_score(target_valid, probabilities_one)\n",
    "\n",
    "print(\"Unbalanced Logistic Regression:\")\n",
    "print(\"Accuracy =\", '{:.4f}'.format(round(accuracy,4)))\n",
    "print(\"F1 Score =\", '{:.4f}'.format(round(F1,4)))\n",
    "print(\"ROC-AUC  =\", '{:.4f}'.format(round(ROCAUC,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Logistic Regression:\n",
      "Accuracy = 0.7010\n",
      "F1 Score = 0.4975\n",
      "ROC-AUC  = 0.7565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=12345, class_weight = 'balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "accuracy = accuracy_score(target_valid, predicted_valid)\n",
    "F1 = f1_score(target_valid, predicted_valid)\n",
    "\n",
    "probabilities = model.predict_proba(features_valid)\n",
    "probabilities_one = probabilities[:, 1]\n",
    "ROCAUC = roc_auc_score(target_valid, probabilities_one)\n",
    "\n",
    "print(\"Balanced Logistic Regression:\")\n",
    "print(\"Accuracy =\", '{:.4f}'.format(round(accuracy,4)))\n",
    "print(\"F1 Score =\", '{:.4f}'.format(round(F1,4)))\n",
    "print(\"ROC-AUC  =\", '{:.4f}'.format(round(ROCAUC,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher *ROC-AUC* is than 0.5, the less random are the predictions, which means that balanced logistic regression's model predictions are less random than imbalanced logistic regression and decision tree models. *F1* as a harmonic mean of recall and precision is also higher, which means that the prediction quality of balanced logistic regression is better too, despite that *Accuracy score* turned out to be lower.\n",
    "<p>I can now conclude the class imbalance. Let's see the random forest.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy = 0.8530\n",
      "F1 Score = 0.5559\n",
      "ROC-AUC  = 0.8131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators = 10)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "accuracy = accuracy_score(target_valid, predicted_valid)\n",
    "F1 = f1_score(target_valid, predicted_valid)\n",
    "\n",
    "probabilities = model.predict_proba(features_valid)\n",
    "probabilities_one = probabilities[:, 1]\n",
    "ROCAUC = roc_auc_score(target_valid, probabilities_one)\n",
    "\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy =\", '{:.4f}'.format(round(accuracy,4)))\n",
    "print(\"F1 Score =\", '{:.4f}'.format(round(F1,4)))\n",
    "print(\"ROC-AUC  =\", '{:.4f}'.format(round(ROCAUC,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is showing the best result in all parameters with the standard number of estimators (10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the model is imbalanced, one can see the superiority of Random Forest Classifier, it means, I need to use this model for further research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fighting Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    " \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat = 01 F1: 0.5542\n",
      "Repeat = 02 F1: 0.5839\n",
      "Repeat = 03 F1: 0.5787\n",
      "Repeat = 04 F1: 0.5848\n",
      "Repeat = 05 F1: 0.5753\n",
      "Repeat = 06 F1: 0.5661\n",
      "Repeat = 07 F1: 0.5729\n",
      "Repeat = 08 F1: 0.5676\n",
      "Repeat = 09 F1: 0.5722\n",
      "Repeat = 10 F1: 0.5508\n"
     ]
    }
   ],
   "source": [
    "for repeat in range(1,11,1):\n",
    "    features_upsampled, target_upsampled = upsample(features_train, target_train, repeat)\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators = 10)\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid = model.predict(features_valid) \n",
    "    F1 = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Repeat =\", str(repeat).zfill(2), \"F1:\", '{:.4f}'.format(round(F1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With upsampling of a smaller class the dataset is balanced better with 4 time repeat (the highest F1 score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 max_depth = 06 Accuracy = 0.8105 ROC-AUC = 0.8511 F1 Score = 0.6152\n",
      "n_estimators = 10 max_depth = 07 Accuracy = 0.8035 ROC-AUC = 0.8496 F1 Score = 0.5977\n",
      "n_estimators = 10 max_depth = 08 Accuracy = 0.8015 ROC-AUC = 0.8446 F1 Score = 0.5928\n",
      "n_estimators = 10 max_depth = 09 Accuracy = 0.8035 ROC-AUC = 0.8392 F1 Score = 0.5876\n",
      "n_estimators = 10 max_depth = 10 Accuracy = 0.8175 ROC-AUC = 0.8384 F1 Score = 0.5967\n",
      "n_estimators = 10 max_depth = 11 Accuracy = 0.8280 ROC-AUC = 0.8355 F1 Score = 0.6143\n",
      "n_estimators = 15 max_depth = 06 Accuracy = 0.8080 ROC-AUC = 0.8506 F1 Score = 0.6113\n",
      "n_estimators = 15 max_depth = 07 Accuracy = 0.8005 ROC-AUC = 0.8491 F1 Score = 0.5933\n",
      "n_estimators = 15 max_depth = 08 Accuracy = 0.8135 ROC-AUC = 0.8490 F1 Score = 0.6221\n",
      "n_estimators = 15 max_depth = 09 Accuracy = 0.8085 ROC-AUC = 0.8429 F1 Score = 0.5947\n",
      "n_estimators = 15 max_depth = 10 Accuracy = 0.8180 ROC-AUC = 0.8391 F1 Score = 0.6043\n",
      "n_estimators = 15 max_depth = 11 Accuracy = 0.8300 ROC-AUC = 0.8423 F1 Score = 0.6222\n",
      "n_estimators = 20 max_depth = 06 Accuracy = 0.8085 ROC-AUC = 0.8497 F1 Score = 0.6143\n",
      "n_estimators = 20 max_depth = 07 Accuracy = 0.8085 ROC-AUC = 0.8515 F1 Score = 0.6080\n",
      "n_estimators = 20 max_depth = 08 Accuracy = 0.8185 ROC-AUC = 0.8511 F1 Score = 0.6231\n",
      "n_estimators = 20 max_depth = 09 Accuracy = 0.8145 ROC-AUC = 0.8455 F1 Score = 0.6057\n",
      "n_estimators = 20 max_depth = 10 Accuracy = 0.8190 ROC-AUC = 0.8415 F1 Score = 0.6039\n",
      "n_estimators = 20 max_depth = 11 Accuracy = 0.8330 ROC-AUC = 0.8463 F1 Score = 0.6272\n",
      "n_estimators = 25 max_depth = 06 Accuracy = 0.8070 ROC-AUC = 0.8502 F1 Score = 0.6117\n",
      "n_estimators = 25 max_depth = 07 Accuracy = 0.8080 ROC-AUC = 0.8528 F1 Score = 0.6098\n",
      "n_estimators = 25 max_depth = 08 Accuracy = 0.8190 ROC-AUC = 0.8509 F1 Score = 0.6253\n",
      "n_estimators = 25 max_depth = 09 Accuracy = 0.8170 ROC-AUC = 0.8462 F1 Score = 0.6115\n",
      "n_estimators = 25 max_depth = 10 Accuracy = 0.8260 ROC-AUC = 0.8441 F1 Score = 0.6167\n",
      "n_estimators = 25 max_depth = 11 Accuracy = 0.8300 ROC-AUC = 0.8462 F1 Score = 0.6188\n",
      "n_estimators = 30 max_depth = 06 Accuracy = 0.8025 ROC-AUC = 0.8495 F1 Score = 0.6077\n",
      "n_estimators = 30 max_depth = 07 Accuracy = 0.7995 ROC-AUC = 0.8510 F1 Score = 0.6002\n",
      "n_estimators = 30 max_depth = 08 Accuracy = 0.8175 ROC-AUC = 0.8520 F1 Score = 0.6186\n",
      "n_estimators = 30 max_depth = 09 Accuracy = 0.8090 ROC-AUC = 0.8462 F1 Score = 0.5987\n",
      "n_estimators = 30 max_depth = 10 Accuracy = 0.8245 ROC-AUC = 0.8474 F1 Score = 0.6104\n",
      "n_estimators = 30 max_depth = 11 Accuracy = 0.8255 ROC-AUC = 0.8459 F1 Score = 0.6065\n",
      "n_estimators = 35 max_depth = 06 Accuracy = 0.8015 ROC-AUC = 0.8506 F1 Score = 0.6089\n",
      "n_estimators = 35 max_depth = 07 Accuracy = 0.8045 ROC-AUC = 0.8517 F1 Score = 0.6078\n",
      "n_estimators = 35 max_depth = 08 Accuracy = 0.8200 ROC-AUC = 0.8528 F1 Score = 0.6226\n",
      "n_estimators = 35 max_depth = 09 Accuracy = 0.8150 ROC-AUC = 0.8473 F1 Score = 0.6089\n",
      "n_estimators = 35 max_depth = 10 Accuracy = 0.8245 ROC-AUC = 0.8472 F1 Score = 0.6087\n",
      "n_estimators = 35 max_depth = 11 Accuracy = 0.8240 ROC-AUC = 0.8465 F1 Score = 0.6018\n",
      "n_estimators = 40 max_depth = 06 Accuracy = 0.8055 ROC-AUC = 0.8510 F1 Score = 0.6098\n",
      "n_estimators = 40 max_depth = 07 Accuracy = 0.8080 ROC-AUC = 0.8530 F1 Score = 0.6129\n",
      "n_estimators = 40 max_depth = 08 Accuracy = 0.8210 ROC-AUC = 0.8536 F1 Score = 0.6232\n",
      "n_estimators = 40 max_depth = 09 Accuracy = 0.8165 ROC-AUC = 0.8483 F1 Score = 0.6083\n",
      "n_estimators = 40 max_depth = 10 Accuracy = 0.8245 ROC-AUC = 0.8477 F1 Score = 0.6096\n",
      "n_estimators = 40 max_depth = 11 Accuracy = 0.8265 ROC-AUC = 0.8458 F1 Score = 0.6052\n",
      "n_estimators = 45 max_depth = 06 Accuracy = 0.8085 ROC-AUC = 0.8509 F1 Score = 0.6120\n",
      "n_estimators = 45 max_depth = 07 Accuracy = 0.8020 ROC-AUC = 0.8531 F1 Score = 0.6032\n",
      "n_estimators = 45 max_depth = 08 Accuracy = 0.8225 ROC-AUC = 0.8541 F1 Score = 0.6251\n",
      "n_estimators = 45 max_depth = 09 Accuracy = 0.8165 ROC-AUC = 0.8487 F1 Score = 0.6116\n",
      "n_estimators = 45 max_depth = 10 Accuracy = 0.8245 ROC-AUC = 0.8496 F1 Score = 0.6096\n",
      "n_estimators = 45 max_depth = 11 Accuracy = 0.8245 ROC-AUC = 0.8472 F1 Score = 0.6016\n",
      "n_estimators = 50 max_depth = 06 Accuracy = 0.8085 ROC-AUC = 0.8508 F1 Score = 0.6127\n",
      "n_estimators = 50 max_depth = 07 Accuracy = 0.8025 ROC-AUC = 0.8533 F1 Score = 0.6062\n",
      "n_estimators = 50 max_depth = 08 Accuracy = 0.8245 ROC-AUC = 0.8543 F1 Score = 0.6294\n",
      "n_estimators = 50 max_depth = 09 Accuracy = 0.8185 ROC-AUC = 0.8488 F1 Score = 0.6142\n",
      "n_estimators = 50 max_depth = 10 Accuracy = 0.8230 ROC-AUC = 0.8500 F1 Score = 0.6084\n",
      "n_estimators = 50 max_depth = 11 Accuracy = 0.8280 ROC-AUC = 0.8478 F1 Score = 0.6073\n"
     ]
    }
   ],
   "source": [
    "for estim in range(10, 51, 5):\n",
    "    for depth in range(6,12,1):\n",
    "        model = RandomForestClassifier(n_estimators=estim, max_depth=depth, random_state=12345)\n",
    "        model.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        \n",
    "        accuracy = accuracy_score(target_valid, predicted_valid)\n",
    "        F1 = f1_score(target_valid, predicted_valid)\n",
    "        probabilities = model.predict_proba(features_valid)\n",
    "        probabilities_one = probabilities[:, 1]\n",
    "        ROCAUC = roc_auc_score(target_valid, probabilities_one)\n",
    "        \n",
    "        print(\"n_estimators =\", str(estim).zfill(2),\n",
    "              \"max_depth =\", str(depth).zfill(2),\n",
    "              \"Accuracy =\", '{:.4f}'.format(round(accuracy, 4)),\n",
    "              \"ROC-AUC =\",'{:.4f}'.format(round(ROCAUC, 4)),\n",
    "              \"F1 Score =\", '{:.4f}'.format(round(F1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 0.8265 and 0.826 the model has shown the best third result in *Accuracy score* which is equal to 0.8245 when number of estimators is 50 and max depth is 8, but with these hyperparameters the quality of the model turned to be the highest in *ROC-AUC* and *F1 Score* metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat = 0.90 Accuracy = 0.8035 ROC-AUC = 0.8524 F1 = 0.6090\n",
      "Repeat = 0.91 Accuracy = 0.8005 ROC-AUC = 0.8491 F1 = 0.6038\n",
      "Repeat = 0.92 Accuracy = 0.8065 ROC-AUC = 0.8552 F1 = 0.6126\n",
      "Repeat = 0.93 Accuracy = 0.8145 ROC-AUC = 0.8550 F1 = 0.6203\n",
      "Repeat = 0.94 Accuracy = 0.8065 ROC-AUC = 0.8554 F1 = 0.6111\n",
      "Repeat = 0.95 Accuracy = 0.8105 ROC-AUC = 0.8559 F1 = 0.6183\n",
      "Repeat = 0.96 Accuracy = 0.8115 ROC-AUC = 0.8511 F1 = 0.6133\n",
      "Repeat = 0.97 Accuracy = 0.8135 ROC-AUC = 0.8546 F1 = 0.6198\n",
      "Repeat = 0.98 Accuracy = 0.8105 ROC-AUC = 0.8522 F1 = 0.6129\n",
      "Repeat = 0.99 Accuracy = 0.8135 ROC-AUC = 0.8519 F1 = 0.6182\n",
      "Repeat = 1.00 Accuracy = 0.8105 ROC-AUC = 0.8545 F1 = 0.6137\n"
     ]
    }
   ],
   "source": [
    "for repeat in np.arange(0.9, 1.01, 0.01):\n",
    "    features_downsampled, target_downsampled = downsample(features_upsampled, target_upsampled, repeat)\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=50, max_depth = 8)\n",
    "    model.fit(features_downsampled, target_downsampled)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    \n",
    "    accuracy = accuracy_score(target_valid, predicted_valid)\n",
    "    probabilities = model.predict_proba(features_valid)\n",
    "    probabilities_one = probabilities[:, 1]\n",
    "    ROCAUC = roc_auc_score(target_valid, probabilities_one)\n",
    "    F1 = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Repeat =\", '{:.2f}'.format(round(repeat, 2)),\n",
    "          \"Accuracy =\", '{:.4f}'.format(round(accuracy,4)),\n",
    "          \"ROC-AUC =\", '{:.4f}'.format(round(ROCAUC, 4)), \n",
    "          \"F1 =\", '{:.4f}'.format(round(F1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and F1 are showing the best results with repeat = 0.93, ROC-AUC is comparably great too, only slightly lower than the other iterations and still higher than most of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need the following hyperparameters in order to improve the quality of the model:\n",
    "\n",
    "- n_estimators = 50 \n",
    "- max_depth = 8\n",
    "\n",
    "and for the right class balance I need to upsample the small class in 4 times and downsample the big one in 0.93."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([features_train, features_valid])\n",
    "target = pd.concat([target_train, target_valid]) #concatenating training and validation sets\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features, target, 4)\n",
    "features_downsampled, target_downsampled = downsample(features_upsampled, target_upsampled, 0.93) #upsampling + downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining the train and validation data sets by considering the class imbalance before building the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8040 ROC-AUC = 0.9168 F1 = 0.6164\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=50, max_depth = 8)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_test = model.predict(features_test)\n",
    "\n",
    "probabilities = model.predict_proba(features)\n",
    "probabilities_one = probabilities[:, 1]\n",
    "accuracy = accuracy_score(target_test, predicted_test)\n",
    "ROCAUC = roc_auc_score(target, probabilities_one)\n",
    "F1 = f1_score(target_test, predicted_test)\n",
    "\n",
    "print(\"Accuracy =\", '{:.4f}'.format(round(accuracy, 4)),\n",
    "      \"ROC-AUC =\",  '{:.4f}'.format(round(ROCAUC, 4)), \n",
    "      \"F1 =\", '{:.4f}'.format(round(F1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of metrics gained during the test is similar to the validation. The model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "According to the test, the model could almost reach the same metric results with Accuracy (0.804) and F1 Scores (0.6164) as during validation (0.8105 and 0.6202, accordingly), ROC-AUC score has grown due to the larger dataset size, the model's predictions are generated less randomly than before."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
